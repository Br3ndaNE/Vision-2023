{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.load_data import load_train, load_test, load_example\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image recognition met een \"normaal\" neuraal netwerk. \n",
    "\n",
    "Neurale netwerken zijn ontzettend sterke wiskundige modellen. Een “normaal” neuraal netwerk heeft echter wel wat limieten. Om een aantal van deze limieten te doorbreken, kan je een convolutional neuraal netwerk gebruiken. \n",
    "\n",
    "We beginnen met het exploreren van de limieten van normale neurale netwerken, dit doen we doormiddel van de MNIST-dataset.\n",
    "\n",
    "MNIST is een dataset van 70.000 handgeschreven cijfers (0..9), opgesplitst in 60.000 training images en 10.000 testing images. We hebben al functies geschreven waarmee je de data kan inladen, zie de cell hieronder.\n",
    "\n",
    "Deze data is steeds opgedeeld in 2 stukken: train en labels.\n",
    "\n",
    "train is een (numpy) array met alle inputafbeeldingen erin.\n",
    "labels is een (numpy) array met voor elke inputafbeelding de werkelijke waarde.\n",
    "\n",
    "Als train[5] een afbeelding van een 4 is, dan geldt dus: labels[5] == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Laad de trainingsdata en labels\n",
    "(train_data, train_labels),(test_data, test_labels) = load_data()\n",
    "\n",
    "# De kleurwaarden in de afbeelding zijn nu 0 tot 255, we zetten deze om naar -0.5 tot 0.5\n",
    "train_data = (train_data / 255) - 0.5\n",
    "\n",
    "\n",
    "plt.imshow(train_data[2])\n",
    "plt.title(f\"{train_labels[2]}\")\n",
    "print(f\"Label: {train_labels[2]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data formatting\n",
    "Voordat we een neuraal netwerk kunnen trainen op de MNIST-data, moet deze verwerkt worden.\n",
    "\n",
    "De input data zijn op het moment grijsafbeeldingen, en dus 2-dimensionaal (x,y).\n",
    "Alleen elke input van dit neuraal netwerk moet 1-dimensionaal zijn. Probeer nu zelf train_data om te zetten naar een\n",
    "correct format. De labels hebben wij zelf al voor je omgezet naar het juiste formaat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels, 10)\n",
    "train_data = np.array([i.reshape(-1)  for i in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handig om te weten: Image recognition geeft in het algemeen ontzettend grote input vectors.\n",
    "MNIST is in grayscale, maar veel plaatjes zijn dat niet. Als je ook nog kleur wil meegeven,\n",
    "zou de input vector nog drie keer zo groot zijn.\n",
    "\n",
    "### Bouwen van een NN\n",
    "\n",
    "De volgende stap is om een neuraal netwerk te bouwen.\n",
    "Maak zelf de eerste Dense layer af, kijk vervolgens ook naar hoeveel hidden layers je toevoegt.\n",
    "Bij image recognition is de activation function ook erg belangrijk.\n",
    "Denk goed na over welke je gebruikt. De laatste layer geven wij alvast aan je.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brendan\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m25,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,450</span> (99.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,450\u001b[0m (99.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,450</span> (99.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,450\u001b[0m (99.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# input_dim moet gelijk zijn aan de lengte van 1 input\n",
    "model.add(Dense(32, input_dim=784)) # FIXME\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieruit kan je al direct het eerste probleem van normale neurale netwerken inzien; er is een gigantische hoeveelheid trainbare parameters. \n",
    "\n",
    "Iedere node moet verbonden zijn aan iedere node. Bij image recognition is de input vector gigantisch, dit houdt dus ook in dat er een gigantische hoeveelheid weights zijn waarmee jouw neuraal netwerk rekening moet houden. \n",
    "\n",
    "Dit maakt het trainen best zwaar en langzaam.\n",
    "\n",
    "Het klaarmaken van een neural network in Keras heeft de volgende stappen:\n",
    "- Aangeven van de layers, dit hebben we net gedaan\n",
    "- Compilen, het model word nu geconfigureerd om hem klaar te maken voor trainen\n",
    "- Fit, het model word nu \"getraind\" op data die je meegeeft. Hieraan geef je zowel data als labels mee\n",
    "- Evaluate; Controller het model om te kijken of het accuraat is. Geef hieraan data en labels mee, maar zorg dat deze data niet ook in je trainingsdata zit\n",
    "- Predict; Geef inputdata mee, waarvan je het label nog niet kent. het NN probeert het label nu te bedenken.\n",
    "Ga nu door met het trainen van dit neuraal netwerk. Ook de `.compile()` hebben wij al aan je geven, ook hier mag je mee spelen.\n",
    "\n",
    "Probeer jouw neuraal netwerk zo accuraat mogelijk te maken. (doe dit door te kijken naar de resultaten van de `.fit()`; `.evaluate()` komt later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In AI is het aantal epochs het aantal keer dat je over de volledige dataset heen gaat om te trainen.\n",
    "\n",
    "Experimenteer met deze waarde om te kijken wat voor invloed deze heeft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.8245 - loss: 0.5940\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.9024 - loss: 0.3379\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - accuracy: 0.9071 - loss: 0.3218\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - accuracy: 0.9141 - loss: 0.3048\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576us/step - accuracy: 0.9165 - loss: 0.2985\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582us/step - accuracy: 0.9142 - loss: 0.2977\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.9156 - loss: 0.2954\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.9148 - loss: 0.2962\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.9176 - loss: 0.2871\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - accuracy: 0.9179 - loss: 0.2857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ac19ea3750>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, epochs=10) # FIXME set epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Het evalueren van het neurale netwerk\n",
    "Ook hier moet de data eerst nog omgevormd worden, gebruik hiervoor dezelfde code als bij de training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = test_data/255.0 - 0.5\n",
    "\n",
    "\n",
    "test_data = np.array([i.flatten()  for i in test_data])\n",
    "test_labels = to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.8959 - loss: 0.3547\n",
      "loss: 0.3087780177593231, accuracy: 0.9100000262260437 van de 1.0\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(f\"loss: {result[0]}, accuracy: {result[1]} van de 1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huh?\n",
    "Hoogstwaarschijnlijk scoort jouw neuraal netwerk nu ontzettend slecht. Om een limiet van neurale netwerken zichtbaar te maken, hebben we een klein beetje valsgespeeld. We hebben wat padding toegevoegd; een aantal pixels aan de linkerkant bij de testing data en een aantal pixels aan de rechterkant bij de training data. Zie de plots hieronder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m (example_r, example_l), label \u001b[38;5;241m=\u001b[39m \u001b[43mload_example\u001b[49m()\n\u001b[0;32m      2\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m      4\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mimshow(example_r)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_example' is not defined"
     ]
    }
   ],
   "source": [
    "(example_r, example_l), label = load_example()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].imshow(example_r)\n",
    "axs[0].set_title(\"Padding on right side (Like training)\")\n",
    "\n",
    "axs[1].imshow(example_l)\n",
    "axs[1].set_title(\"Padding on left side (Like testing)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De standaardwaarde voor de padding is 3(!!) pixels, dit heeft een gigantisch effect op de accuratesse.\n",
    "Formatteer nog één keer de data (`examples`), en kijk wat er uit de `.predict()` komt.\n",
    "\n",
    "Er bestaat een kans dat jouw model hier de goede voorspelt, probeer dan bij `load_example()` het argument `index` te veranderen naar een ander getal. Waarschijnlijk zal het dan wel fout voorspellen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = np.array([example_r.flatten(), example_l.flatten()]) # FIXME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waarom?\n",
    "\n",
    "De voorspellingen van een gewoon neuraal netwerk zijn ruimtelijk bepaald, het herkent patronen op specifieke plekken. Het verplaatsen van deze patronen met maar een paar pixels kan al genoeg zijn om het onmogelijk te maken voor een gewoon neuraal netwerk om deze te herkennen. \n",
    "\n",
    "Een neuraal netwerk getraind op het herkennen van honden en fietsen, zou heel makkelijk het volgende gedrag kunnen laten zien:\n",
    "\n",
    "\n",
    "\n",
    "![Right!](src/top-left-dog.png)\n",
    "\n",
    "![Wrong!](src/top-left-bike.png)\n",
    "\n",
    "\n",
    "Speel is een beetje rond met de padding, kijk is hoeveel impact 4 pixels heeft, zelfs 1 pixel kan al een grote impact hebben!\n",
    "\n",
    "Wij raden aan om alleen de horizontale padding te veranderen, het format van het padding argument in `load_train`, `load_test`, en `load_example` is dan: `((0, 0), (0, 0), (left sided padding, right sided padding))`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aldewereld, H. & van der Bijl, B. & Bunk, J. (2017, oktober). Applied Artificial Intelligence. Geraadpleegd op 13 maart 2020, van https://canvas.hu.nl/courses/7569/files/694738/download?wrap=1\n",
    "\n",
    "- Chollet, F. (2019, November 6). Getting started with the Keras Sequential model. Geraadpleegd op 13 maart 2020, van keras.io: https://keras.io/getting-started/sequential-model-guide/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
